{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from JapaneseTokenizer import MecabWrapper, JumanWrapper, JumanppWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert Text to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2sentence_list(text):\n",
    "    sentence_list = [sentence.strip() for sentence in text.split('。')]\n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize Sentences (Mecab and Juman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpTokenizerMecab(text):\n",
    "    sentence_list = text2sentence_list(text)\n",
    "    sentence_list_token = []\n",
    "    mecab_wrapper = MecabWrapper(dictType='neologd')\n",
    "    for sentence in sentence_list:\n",
    "        sentence_token = mecab_wrapper.tokenize(sentence=sentence, \n",
    "                                                is_feature=False, is_surface=False)\n",
    "        #sentence_token.filter(stopwords=stopWordsList)\n",
    "        sentence_list_token.append(sentence_token.convert_list_object())\n",
    "    return sentence_list_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpTokenizerJuman(text):\n",
    "    sentence_list = text2sentence_list(text)\n",
    "    sentence_list_token = []\n",
    "    juman_wrapper = JumanWrapper()\n",
    "    for sentence in sentence_list:\n",
    "        sentence_token = juman_wrapper.tokenize(sentence=sentence, \n",
    "                                                is_feature=False, is_surface=False)\n",
    "        #sentence_token.filter(stopwords=stopWordsList)\n",
    "        sentence_list_token.append(sentence_token.convert_list_object())\n",
    "    return sentence_list_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"２月２７～２８日の米朝首脳会談で、トランプ米大統領が北朝鮮の金正恩キムジョンウン朝鮮労働党委員長に日本人拉致問題を提起したのは、初日に行われた１対１の会談の冒頭だったことがわかった。\n",
    "\n",
    "　複数の日本政府関係者が明らかにした。\n",
    "\n",
    "　安倍首相は２月２０日のトランプ氏との電話会談で、拉致問題を正恩氏に提起するよう要請した。トランプ氏の発言は、これに配慮したものとみられる。正恩氏は核・ミサイル問題が最初の議題と想定していたのか、その場で「驚いた表情」を見せたという。\n",
    "\n",
    "　トランプ氏は１対１の会談に続き、２７日の夕食会でも拉致問題を取り上げた。日本政府は「首相の注文通り」（関係者）と歓迎している。政府は日米連携をテコに日朝の首脳による直接対話につなげ、拉致問題を打開したい考えだ。\"\"\"\n",
    "stopWordsList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2月',\n",
       "  '2728',\n",
       "  '日',\n",
       "  'の',\n",
       "  '米朝首脳会談',\n",
       "  'で',\n",
       "  '、',\n",
       "  'トランプ',\n",
       "  '米大統領',\n",
       "  'が',\n",
       "  '北朝鮮',\n",
       "  'の',\n",
       "  '金正恩',\n",
       "  'キム・ジョンウン',\n",
       "  '朝鮮労働党委員長',\n",
       "  'に',\n",
       "  '日本人拉致',\n",
       "  '問題',\n",
       "  'を',\n",
       "  '提起',\n",
       "  'する',\n",
       "  'た',\n",
       "  'の',\n",
       "  'は',\n",
       "  '、',\n",
       "  '初日',\n",
       "  'に',\n",
       "  '行う',\n",
       "  'れる',\n",
       "  'た',\n",
       "  '1',\n",
       "  '対',\n",
       "  '1',\n",
       "  'の',\n",
       "  '会談',\n",
       "  'の',\n",
       "  '冒頭',\n",
       "  'だ',\n",
       "  'た',\n",
       "  'こと',\n",
       "  'が',\n",
       "  'わかる',\n",
       "  'た'],\n",
       " ['複数', 'の', '日本政府', '関係者', 'が', '明らか', 'に', 'する', 'た'],\n",
       " ['安倍首相',\n",
       "  'は',\n",
       "  '2月20日',\n",
       "  'の',\n",
       "  'トランプ',\n",
       "  '氏',\n",
       "  'と',\n",
       "  'の',\n",
       "  '電話会談',\n",
       "  'で',\n",
       "  '、',\n",
       "  '拉致問題',\n",
       "  'を',\n",
       "  '正',\n",
       "  '恩',\n",
       "  '氏',\n",
       "  'に',\n",
       "  '提起',\n",
       "  'する',\n",
       "  'よう',\n",
       "  '要請',\n",
       "  'する',\n",
       "  'た'],\n",
       " ['ドナルド・トランプ',\n",
       "  'の',\n",
       "  '発言',\n",
       "  'は',\n",
       "  '、',\n",
       "  'これ',\n",
       "  'に',\n",
       "  '配慮',\n",
       "  'する',\n",
       "  'た',\n",
       "  'もの',\n",
       "  'と',\n",
       "  'みる',\n",
       "  'られる'],\n",
       " ['正',\n",
       "  '恩氏',\n",
       "  'は',\n",
       "  '核',\n",
       "  '・',\n",
       "  'ミサイル',\n",
       "  '問題',\n",
       "  'が',\n",
       "  '最初',\n",
       "  'の',\n",
       "  '議題',\n",
       "  'と',\n",
       "  '想定',\n",
       "  'する',\n",
       "  'て',\n",
       "  'いる',\n",
       "  'た',\n",
       "  'の',\n",
       "  'か',\n",
       "  '、',\n",
       "  'その',\n",
       "  '場',\n",
       "  'で',\n",
       "  '「',\n",
       "  '驚く',\n",
       "  'た',\n",
       "  '表情',\n",
       "  '」',\n",
       "  'を',\n",
       "  '見せる',\n",
       "  'た',\n",
       "  'という'],\n",
       " ['ドナルド・トランプ',\n",
       "  'は',\n",
       "  '1',\n",
       "  '対',\n",
       "  '1',\n",
       "  'の',\n",
       "  '会談',\n",
       "  'に',\n",
       "  '続く',\n",
       "  '、',\n",
       "  '27日',\n",
       "  'の',\n",
       "  '夕食',\n",
       "  '会',\n",
       "  'で',\n",
       "  'も',\n",
       "  '拉致問題',\n",
       "  'を',\n",
       "  '取り上げる',\n",
       "  'た'],\n",
       " ['日本政府',\n",
       "  'は',\n",
       "  '「',\n",
       "  '首相',\n",
       "  'の',\n",
       "  '注文',\n",
       "  '通り',\n",
       "  '」(',\n",
       "  '関係者',\n",
       "  ')',\n",
       "  'と',\n",
       "  '歓迎',\n",
       "  'する',\n",
       "  'て',\n",
       "  'いる'],\n",
       " ['政府',\n",
       "  'は',\n",
       "  '日',\n",
       "  '米',\n",
       "  '連携',\n",
       "  'を',\n",
       "  'テコ',\n",
       "  'に',\n",
       "  '日朝',\n",
       "  'の',\n",
       "  '首脳',\n",
       "  'による',\n",
       "  '直接',\n",
       "  '対話',\n",
       "  'に',\n",
       "  'つなげる',\n",
       "  '、',\n",
       "  '拉致問題',\n",
       "  'を',\n",
       "  '打開',\n",
       "  'する',\n",
       "  'たい',\n",
       "  '考え',\n",
       "  'だ'],\n",
       " []]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = jpTokenizerMecab(text)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
